<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Temario</title>
</head>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 20px;
    }

    h1, h2 {
        text-align: center;
    }

    table {
        border-collapse: collapse;
        width: 100%;
        margin: 20px 0;
    }

    th, td {
        border: 1px solid #dddddd;
        text-align: left;
        padding: 8px;
    }

    th {
        background-color: #f0f0f0;
    }
</style>
<body>

    <h1> Tema 1 </h1>

<h2>1.1 Conceptos básicos de estadística</h2>

<h3>Definición</h3>
<p>La estadística es la ciencia que se encarga de la recolección, organización, análisis e interpretación de datos para extraer información útil y tomar decisiones acertadas.</p>

<h3>Ramas de la estadística</h3>

<ul>
  <li><strong>Estadística descriptiva:</strong> Describe las características de los datos mediante medidas como la media, la mediana, la moda y la desviación estándar.</li>
  <li><strong>Estadística inferencial:</strong> Permite sacar conclusiones sobre una población a partir de una muestra aleatoria.</li>
</ul>

<h3>Teoría de la decisión</h3>

<p>Es una rama de la estadística que se enfoca en la toma de decisiones bajo incertidumbre. Brinda herramientas para evaluar diferentes opciones y elegir la que maximice la probabilidad de un resultado favorable.</p>

<h3>Población</h3>

<p>Es el conjunto completo de elementos o individuos que se estudian. Puede ser finito o infinito. En la práctica, es difícil o imposible trabajar con toda la población, por lo que se recurre a una muestra.</p>

<h3>Muestra aleatoria</h3>

<p>Es un subconjunto de la población seleccionado de tal manera que cada elemento tiene la misma probabilidad de ser elegido. La aleatoriedad garantiza que la muestra sea representativa de la población.</p>

<h3>Parámetros aleatorios</h3>

<p>Son características desconocidas de la población que se estiman a partir de una muestra. Se representan con letras mayúsculas, como la media poblacional (µ) o la desviación estándar poblacional (σ).</p>

<h3>En resumen</h3>

<p>La estadística es una herramienta fundamental para comprender el mundo que nos rodea y tomar decisiones informadas. Los conceptos básicos de población, muestra, parámetros aleatorios y teoría de la decisión son esenciales para trabajar con datos de manera efectiva.</p>


<h2>1.2 Descripción de datos</h2>  
    <h3>Datos agrupados y no agrupados</h3>
    <p>Los datos **agrupados** se organizan en intervalos (clases) con su respectiva frecuencia. En cambio, los datos **no agrupados** se presentan en su forma original, sin ningún tipo de agrupamiento, listando todos los valores individuales.</p>

    <h3>Frecuencia</h3>
    <ul>
        <li>**Frecuencia absoluta (fi):** Es el número de veces que aparece un valor específico o que cae dentro de un intervalo de clase determinado.</li>
        <li>**Frecuencia relativa (fr):** Es la proporción de datos que caen dentro de un valor específico o un intervalo de clase. Se calcula dividiendo la frecuencia absoluta por el número total de datos (N).</li>
    </ul>

    <h3>Punto medio</h3>
    <p>El punto medio es el valor central de un intervalo de clase. Se calcula sumando el límite inferior y el límite superior y dividiendo por dos.</p>

    <h3>Límites</h3>
    <ul>
        <li>**Límite inferior (Li):** Es el valor mínimo de un intervalo de clase.</li>
        <li>**Límite superior (Ls):** Es el valor máximo de un intervalo de clase.</li>
    </ul>

    <h3>Ejemplo: Edades de 10 estudiantes</h3>
    <p>Consideremos un conjunto de datos que representa las edades de 10 estudiantes: {18, 19, 20, 21, 22, 20, 21, 22, 23, 20}.</p>

    <table>
        <tr>
            <th>Intervalo</th>
            <th>fi</th>
            <th>fr</th>
            <th>M</th>
        </tr>
        <tr>
            <td>18-20</td>
            <td>3</td>
            <td>0.30</td>
            <td>19</td>
        </tr>
        <tr>
            <td>21-23</td>
            <td>4</td>
            <td>0.40</td>
            <td>22</td>
        </tr>
        <tr>
            <td>24-26</td>
            <td>3</td>
            <td>0.30</td>
            <td>25</td>
        </tr>
    </table>

    <p>**Explicación:**</p>
    <ul>
        <li>La tabla muestra las clases (intervalos de edad), su frecuencia absoluta (fi), frecuencia relativa (fr) y punto medio (M).</li>
        <li>Por ejemplo, en la clase 21-23, hay 4 estudiantes (fi) con edades entre 21 y 23 años (representa el 30% de la población, fr).</li>
        <li>El punto medio de la clase 21-23 es 22 años (M).</li>
    </ul>

    <p>**Importancia:**</p>
    <p>La descripción de datos permite organizar, resumir y comprender un conjunto de datos para realizar análisis estadísticos más profundos y tomar decisiones informadas.</p>

<h2>1.3 Medidas de tendencia central</h2>    
<h3>Medidas de tendencia central</h3>
<ul>
    <li>**Media aritmética (X̄):** Es el promedio de un conjunto de datos. Se calcula sumando todos los valores y dividiendo por el número total de datos. Es la medida de tendencia central más común y utilizada.</li>
    <li>**Media geométrica (Xg):** Es el promedio de un conjunto de datos multiplicando todos los valores y luego extrayendo la raíz n-ésima, donde n es el número de datos. Se utiliza cuando se tienen datos con proporciones o porcentajes.</li>
    <li>**Media ponderada (X̄p):** Es el promedio de un conjunto de datos donde cada valor se multiplica por un peso antes de sumarse y dividirse por la suma de los pesos. Se utiliza cuando los datos tienen importancias o valores relativos diferentes.</li>
    <li>**Mediana (Me):** Es el valor central de un conjunto de datos ordenado. Si hay un número par de datos, la mediana es el promedio de los dos valores centrales. Es útil cuando hay valores atípicos o extremos que pueden afectar la media.</li>
    <li>**Moda (Mo):** Es el valor más frecuente en un conjunto de datos. Es útil para identificar el valor más común o popular.</li>
</ul>

<h3>Medidas de dispersión</h3>
<ul>
    <li>**Varianza (σ²):** Es el promedio del cuadrado de las desviaciones de cada valor respecto a la media. Mide la variabilidad de los datos alrededor de la media. Valores más altos de varianza indican mayor dispersión.</li>
    <li>**Desviación estándar (σ):** Es la raíz cuadrada de la varianza. Se expresa en las mismas unidades que los datos originales y proporciona una medida de dispersión absoluta. Valores más altos de desviación estándar indican mayor dispersión.</li>
    <li>**Desviación media (DM):** Es el promedio de las desviaciones absolutas de cada valor respecto a la media. Se expresa en las mismas unidades que los datos originales y es menos sensible a los valores atípicos que la desviación estándar.</li>
    <li>**Desviación mediana (DMe):** Es la mediana de las desviaciones absolutas de cada valor respecto a la mediana. Se expresa en las mismas unidades que los datos originales y es robusta a los valores atípicos.</li>
    <li>**Rango (R):** Es la diferencia entre el valor máximo y el valor mínimo de un conjunto de datos. Mide la amplitud o extensión del conjunto de datos.</li>
</ul>

<h3>Elección de la medida adecuada</h3>
<p>La elección de la medida de tendencia central y dispersión adecuada depende del tipo de datos, la distribución de los datos y el objetivo del análisis.</p>

<h2>1.4 Parámetros para datos agrupados </h2>    
<h3>Definición</h3>
<p>Los datos agrupados se presentan en intervalos de clase (también llamados clases), cada uno con un límite inferior y un límite superior. En este tipo de datos, no se conoce el valor exacto de cada dato, solo la frecuencia de datos que cae dentro de cada intervalo.</p>

<h3>Parámetros de centralización</h3>
<ul>
    <li>**Media aritmética agrupada (X̄g):** Es el promedio de los datos agrupados. Se calcula utilizando la siguiente fórmula:</li>
    <ul>
        <li>`X̄g = Σ (Xi * fi) / N`</li>
        <li>Donde:</li>
        <ul>
            <li>**Xi:** Punto medio del intervalo de clase i</li>
            <li>**fi:** Frecuencia del intervalo de clase i</li>
            <li>**N:** Número total de datos</li>
        </ul>
    </ul>
    <li>**Mediana agrupada (Meg):** Es el valor central de los datos agrupados. Se calcula dividiendo la población acumulada en dos partes iguales.</li>
    <li>**Moda agrupada (Mog):** Es el intervalo de clase con la mayor frecuencia.</li>
</ul>

<h3>Parámetros de dispersión</h3>
<ul>
    <li>**Varianza agrupada (σ²g):** Es el promedio del cuadrado de las desviaciones de los puntos medios de clase respecto a la media aritmética agrupada. Se calcula utilizando la siguiente fórmula:</li>
    <ul>
        <li>`σ²g = Σ [(Xi - X̄g)² * fi] / N`</li>
        <li>Donde:</li>
        <ul>
            <li>**Xi:** Punto medio del intervalo de clase i</li>
            <li>**X̄g:** Media aritmética agrupada</li>
            <li>**fi:** Frecuencia del intervalo de clase i</li>
            <li>**N:** Número total de datos</li>
        </ul>
    </ul>
    <li>**Desviación estándar agrupada (σg):** Es la raíz cuadrada de la varianza agrupada. Se expresa en las mismas unidades que los datos originales y proporciona una medida de dispersión absoluta.</li>
</ul>

<h3>Interpretación y limitaciones</h3>
<p>Los parámetros para datos agrupados permiten estimar las medidas de tendencia central y dispersión de una población a partir de datos agrupados en intervalos. Sin embargo, es importante tener en cuenta las siguientes limitaciones:</p>
<ul>
    <li>La precisión de las estimaciones depende del número de clases y de la amplitud de los intervalos.</li>
    <li>No se puede obtener información sobre la distribución exacta de los datos dentro de cada intervalo.</li>
</ul>

<h3>En resumen</h3>
<p>Los parámetros para datos agrupados son herramientas útiles para analizar conjuntos de datos donde no se conoce el valor exacto de cada dato. Permiten estimar la tendencia central y la dispersión de la población, lo cual puede ser útil para tomar decisiones informadas en diversos contextos.</p>

<h2>1.5 Distribución de frecuencias</h2>    
<p>Una distribución de frecuencias es una herramienta estadística que permite organizar y resumir un conjunto de datos, mostrando la frecuencia con la que aparece cada valor o intervalo de valores.</p>

<h3>Tipos de Distribuciones de Frecuencias</h3>

<h4>Distribución de Frecuencias Simples</h4>
<p>Muestra la frecuencia de cada valor individual en un conjunto de datos.</p>

<h4>Distribución de Frecuencias Agrupadas</h4>
<p>Agrupa los datos en intervalos de clase (también llamados clases) y muestra la frecuencia de cada intervalo.</p>

<h3>Elementos de una Distribución de Frecuencias</h3>

<ul>
  <li><strong>Variable:</strong> La característica que se mide (por ejemplo, altura, edad, ingresos).</li>
  <li><strong>Modalidad:</strong> Los valores o intervalos de valores que se presentan en la distribución.</li>
  <li><strong>Frecuencia Absoluta (fi):</strong> El número de veces que aparece cada modalidad.</li>
  <li><strong>Frecuencia Relativa (fr):</strong> La proporción de datos que cae dentro de cada modalidad. Se calcula dividiendo la frecuencia absoluta por el número total de datos (N).</li>
  <li><strong>Frecuencia Acumulada (Fa):</strong> La suma de las frecuencias absolutas o relativas hasta un determinado valor o intervalo.</li>
</ul>

<h3>Tabla de Frecuencias</h3>
<p>Una tabla de frecuencias es la forma más común de presentar una distribución de frecuencias. Incluye las modalidades, frecuencias absolutas, frecuencias relativas y frecuencias acumuladas.</p>

<h3>Ejemplo</h3>

<p>Edades de 10 estudiantes: {18, 19, 20, 21, 22, 20, 21, 22, 23, 20}</p>

<h4>Distribución de Frecuencias Simples</h4>
<table>
  <thead>
    <tr>
      <th>Edad</th>
      <th>fi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>18</td>
      <td>1</td>
    </tr>
    <tr>
      <td>19</td>
      <td>1</td>
    </tr>
    <tr>
      <td>20</td>
      <td>3</td>
    </tr>
    <tr>
      <td>21</td>
      <td>2</td>
    </tr>
    <tr>
      <td>22</td>
      <td>2</td>
    </tr>
    <tr>
      <td>23</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<h4>Distribución de Frecuencias Agrupadas en Clases de 3 Años</h4>
<table>
  <thead>
    <tr>
      <th>Intervalo</th>
      <th>fi</th>
      <th>fr</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>18-20</td>
      <td>3</td>
      <td>0.30</td>
    </tr>
    <tr>
      <td>21-23</td>
      <td>4</td>
      <td>0.40</td>
    </tr>
    <tr>
      <td>24-26</td>
      <td>3</td>
      <td>0.30</td>
    </tr>
  </tbody>
</table>

<h3>Importancia</h3>
<p>Las distribuciones de frecuencias permiten:</p>
<ul>
  <li>Visualizar la distribución de los datos.</li>
  <li>Identificar la tendencia central de los datos (media, mediana, moda).</li>
  <li>Medir la dispersión de los datos (rango, varianza, desviación estándar).</li>
  <li>Comparar diferentes conjuntos de datos.</li>
</ul>
<p>En resumen, las distribuciones de frecuencias son herramientas esenciales para el análisis descriptivo de datos, ya que permiten organizar, resumir y comprender la distribución de los datos en un conjunto, lo cual es fundamental para tomar decisiones informadas en diversos campos.</p>

<h2>1.6 Técnicas de agrupación de datos</h2>     
<h3>Definición</h3>
<p>Las técnicas de agrupación de datos, también conocidas como clustering o análisis de cluster, son un conjunto de métodos estadísticos que permiten agrupar datos en función de su similitud o cercanía. El objetivo es identificar grupos o clusters de datos que comparten características comunes y diferenciarse de otros grupos.</p>

<h3>Tipos de técnicas de agrupación</h3>
<ul>
    <li>**Basadas en jerarquías:** Agrupan los datos de forma jerárquica, creando una estructura de árbol donde los grupos más pequeños se van uniendo para formar grupos más grandes.</li>
    <li>**Basadas en particiones:** Dividen los datos en un número predefinido de grupos, sin una jerarquía establecida.</li>
    <li>**Basadas en densidad:** Identifican regiones de alta densidad de datos en el espacio multidimensional.</li>
    <li>**Basadas en prototipos:** Representan cada grupo por un prototipo, que es el punto que mejor representa los datos del grupo.</li>
</ul>

<h3>Aplicaciones</h3>
<p>Las técnicas de agrupación de datos se utilizan en una amplia variedad de aplicaciones, incluyendo:</p>
<ul>
    <li>Segmentación de clientes: Identificar grupos de clientes con características similares para desarrollar estrategias de marketing personalizadas.</li>
    <li>Análisis de redes sociales: Identificar comunidades de usuarios con intereses y comportamientos comunes.</li>
    <li>Detección de fraudes: Identificar patrones inusuales en transacciones financieras que podrían indicar un fraude.</li>
    <li>Análisis de imágenes: Identificar objetos o regiones de interés en una imagen.</li>
    <li>Bioinformática: Identificar genes o proteínas con funciones similares.</li>
</ul>

<h3>Beneficios</h3>
<p>Las técnicas de agrupación de datos ofrecen varios beneficios, como:</p>
<ul>
    <li>Descubrimiento de patrones: Identificar patrones ocultos en los datos que podrían ser difíciles de detectar de otra manera.</li>
    <li>Reducción de la dimensionalidad: Simplificar el análisis de datos complejos al agruparlos en dimensiones más pequeñas.</li>
    <li>Mejora de la toma de decisiones: Facilitar la toma de decisiones informadas al proporcionar una mejor comprensión de la estructura de los datos.</li>
</ul>

<h3>Elección de la técnica adecuada</h3>
<p>La elección de la técnica de agrupación de datos adecuada depende de varios factores, como:</p>
<ul>
    <li>El tipo de datos: Los datos numéricos, categóricos o mixtos pueden requerir diferentes técnicas.</li>
    <li>El tamaño del conjunto de datos: Los algoritmos de agrupación pueden ser computacionalmente costosos para conjuntos de datos grandes.</li>
    <li>El objetivo del análisis: La técnica elegida debe estar alineada con el objetivo del análisis.</li>
</ul>

<h3>En resumen</h3>
<p>Las técnicas de agrupación de datos son herramientas poderosas para descubrir patrones en conjuntos de datos complejos y tomar decisiones informadas. La elección de la técnica adecuada depende del tipo de datos, el tamaño del conjunto de datos y el objetivo del análisis.</p>


<h2>1.7 Técnicas de muestreo</h2>   
    <h3>Técnicas de muestreo</h3> 
    <h4>Definición</h4> 
    <p>Las técnicas de muestreo son un conjunto de métodos estadísticos que permiten seleccionar un subgrupo (muestra) de una población más grande, con el objetivo de estudiar las características de la población a partir de los datos obtenidos de la muestra.</p> 
    <h4>Tipos de muestreo</h4>
     <h5>1. Muestreo probabilístico</h5> 
     <ul> 
        <li>Muestreo aleatorio simple (MAS): Cada individuo de la población tiene la misma probabilidad de ser seleccionado. Se puede utilizar una lotería, una tabla de números aleatorios o un generador de números aleatorios.</li> 
        <li>Muestreo aleatorio estratificado (MAE): La población se divide en estratos (grupos homogéneos) y se selecciona una muestra aleatoria de cada estrato.</li> 
        <li>Muestreo aleatorio sistemático (MASi): Se selecciona un punto de partida aleatorio en la población y se seleccionan individuos a intervalos regulares.</li> 
        <li>Muestreo por conglomerados: La población se divide en conglomerados (grupos de individuos) y se selecciona una muestra aleatoria de conglomerados.</li> 
    </ul> 
    
    <h5>2. Muestreo no probabilístico</h5> 
    <ul> 
        <li>Muestreo por conveniencia: Se seleccionan los individuos que son fáciles de acceder o que están disponibles.</li> 
        <li>Muestreo intencional: Se seleccionan los individuos que se consideran representativos de la población o que tienen características específicas.</li> 
        <li>Muestreo por cuotas: Se establecen cuotas para cada subgrupo de la población y se seleccionan individuos hasta que se cumplan las cuotas.</li>
     </ul> 
     
     <h4>Selección de la técnica de muestreo</h4> 
     <p>La elección de la técnica de muestreo adecuada depende de varios factores, como:</p> 
     <ul> 
        <li>El tamaño y la diversidad de la población: Si la población es grande y diversa, es importante utilizar una técnica de muestreo probabilística para garantizar que la muestra sea representativa.</li> 
        <li>Los recursos disponibles: Algunas técnicas de muestreo, como el muestreo aleatorio estratificado, requieren más recursos que otras.</li>
         <li>Los objetivos del estudio: La técnica de muestreo debe elegirse en función de los objetivos específicos del estudio.</li>
         </ul> 
         
         <h4>Beneficios del muestreo</h4>
         <ul>
             <li>Reducción de costos: Es más económico estudiar una muestra que toda la población.</li> 
             <li>Ahorro de tiempo: Se puede recopilar y analizar datos de una muestra más rápidamente que de toda la población.</li>
             <li>Mayor precisión: En algunos casos, el muestreo puede proporcionar resultados más precisos que un estudio de toda la población.</li> 
            </ul>
            
            <h4>Limitaciones del muestreo</h4> 
            <ul>
                 <li>Error muestral: La diferencia entre las características de la muestra y las de la población.</li> 
                 <li>Sesgo muestral: Cuando la muestra no es representativa de la población.</li> 
                </ul>
                
            <h2>En resumen</h2>
            <p>Las técnicas de muestreo son herramientas esenciales para estudiar poblaciones a partir de muestras más pequeñas. La elección de la técnica adecuada depende de varios factores, como el tamaño y la diversidad de la población, los recursos disponibles y los objetivos del estudio</p>

<h2>1.8. Histogramas</h2>
        <p>Los histogramas son gráficos de barras que representan la distribución de frecuencia de una variable cuantitativa continua.</p>

  <h2>Estructura de un histograma en HTML</h2>

  <ul>
    <li><strong>Eje horizontal:</strong> Representado por una etiqueta con la altura mínima necesaria. El ancho se ajusta a la cantidad de intervalos.</li>
    <li><strong>Eje vertical:</strong> Representado por una etiqueta con el ancho mínimo necesario. La altura se ajusta al rango máximo de frecuencias.</li>
    <li><strong>Barras:</strong> Dibujadas utilizando JavaScript o bibliotecas de visualización de datos como Chart.js o D3.js.</li>
  </ul>

  <h2>Ejemplo de código HTML básico</h2>
<p>
  ```javascript<br>
  // Definición de datos de ejemplo<br>
  const data = [10, 15, 20, 22, 18, 25, 30, 27, 23, 28];<br>

  // Creación de elementos canvas para el eje horizontal y vertical<br>
  const horizontalAxisCanvas = document.getElementById('horizontalAxis');<br>
  const verticalAxisCanvas = document.getElementById('verticalAxis');<br>

  // Obtención de contextos de dibujo para cada canvas<br>
  const horizontalAxisCtx = horizontalAxisCanvas.getContext('2d');<br>
  const verticalAxisCtx = verticalAxisCanvas.getContext('2d');<br>

  // Definición de parámetros del histograma (intervalos, frecuencias, etc.)<br>
  // ...<br>

  // Dibujo de las barras del histograma<br>
  // ...
</p>

<h1>Tema 2</h1>

<h2>2.1 Técnicas de Conteo</h2>

<h3>Principio aditivo</h3>
<p>El principio aditivo establece que si una tarea se puede realizar de A maneras o de B maneras, 
  entonces se puede realizar de A + B maneras. Este principio se utiliza para calcular el número total 
  de posibilidades cuando hay alternativas mutuamente excluyentes.</p>

<h3>Principio multiplicativo</h3>
<p>El principio multiplicativo establece que si una tarea se puede realizar de A maneras y, 
  después, otra tarea se puede realizar de B maneras, entonces ambas tareas se pueden realizar de 
  A * B maneras. Este principio se utiliza para calcular el número total de posibilidades cuando las 
  tareas se realizan de manera secuencial.</p>

<h3>Notación Factorial</h3>
<p>La notación factorial se representa como n! y se define como el producto de todos los números
   enteros positivos desde 1 hasta n. Se utiliza para calcular el número de permutaciones de n elementos.</p>

<h3>Permutaciones</h3>
<p>Las permutaciones representan el número de formas en que se pueden ordenar n elementos. 
  La fórmula para calcular el número de permutaciones de n elementos es: n!</p>

<h3>Combinaciones</h3>
<p>Las combinaciones representan el número de formas en que se pueden seleccionar k 
  elementos de un conjunto de n elementos, sin importar el orden. La fórmula para calcular el número de 
  combinaciones de n elementos tomados de k en k es: nCk = n! / (k! * (n-k)!)</p> 

<h3>Diagrama de Árbol</h3>
<p>El diagrama de árbol es una representación gráfica que muestra todas las posibles secuencias de 
  eventos o resultados en un problema de conteo. Resulta útil para visualizar y entender las diferentes posibilidades.</p>

<h3>Teorema del Binomio</h3>
<p>El teorema del binomio establece que la expresión (a + b)^n se puede expandir en una suma de términos que involucran 
  coeficientes binomiales. La fórmula general es: (a + b)^n = Σ (n!/(k!(n-k)!)) * a^(n-k) * b^k, donde k varía de 0 a n.</p>


<h2>2.2 Teoría elemental de probabilidad</h2>


<p>La probabilidad es una rama de las matemáticas que estudia la medición de la incertidumbre. La teoría elemental de probabilidad se enfoca en conceptos básicos como:</p>

<ul>
  <li><strong>Espacio muestral:</strong> 
    Es el conjunto de todos los posibles resultados de un experimento aleatorio.</li>
  <li><strong>Evento:</strong>
    Es cualquier subconjunto del espacio muestral. Los eventos pueden ser simples (un solo resultado) o compuestos (una combinación de resultados).</li>
  <li><strong>Probabilidad:</strong>
    Es una medida que cuantifica la posibilidad de que ocurra un evento. Toma valores entre 0 y 1, donde 0 significa que el evento es imposible y 1 significa que el evento es seguro.</li>
  <li><strong>Operaciones con eventos:</strong>
    Se pueden realizar operaciones como unión, intersección y complemento entre eventos para analizar la probabilidad de eventos más complejos.</li>
  <li><strong>Reglas de probabilidad:</strong> 
    Existen reglas básicas como la probabilidad de la unión de eventos, la probabilidad condicional y el teorema de Bayes, que permiten calcular probabilidades de manera sistemática.</li>
  <li><strong>Variables aleatorias:</strong>
    Son funciones que asignan un valor numérico a cada resultado del experimento aleatorio. Pueden ser discretas o continuas.</li>
  <li><strong>Distribuciones de probabilidad:</strong>
    Describen el comportamiento de las variables aleatorias y permiten calcular probabilidades de eventos relacionados con ellas.</li>
</ul>


<h2>2.3 Probabilidad de Eventos</h2>
 
<h3>Espacio muestral</h3>
 <p>El espacio muestral, denotado por <strong>Ω</strong>, es el conjunto de todos los posibles resultados de un experimento aleatorio.
   Representa el universo de posibilidades para un determinado experimento.</p>
 
<h3>Evento</h3>
 <p>Un evento es cualquier subconjunto del espacio muestral <strong>Ω</strong>. Puede ser un evento simple (un solo resultado) o un evento
   compuesto (una combinación de resultados). Los eventos se denotan generalmente con letras mayúsculas, como <strong>A, B, C,</strong> etc.</p>


<h3>Simbología</h3> 
<ul> 
  <li>muestral:<strong>Ω</strong>  </li> 
  <li>Evento:<strong>A, B, C, etc.</strong> </li> 
  <li>Unión de eventos: <strong>A ∪ B</strong> </li> 
  <li>Intersección de eventos: <strong>A ∩ B</strong></li> 
  <li>Complemento de un evento: <strong>A'</strong></li> 
</ul>

<h3>Unión de eventos</h3>
 <p>La unión de dos eventos <strong> A y B, </strong> denotada como <strong> A ∪ B, </strong>es el evento que ocurre cuando ocurre al menos uno de los dos eventos.</p> 


<h3>Intersección de eventos</h3> 
<p>La intersección de dos eventos <strong>A</strong> y <strong>B,</strong> denotada como <strong>A ∩ B,</strong> es el evento que ocurre cuando ocurren ambos eventos simultáneamente.</p> 
 

<h3>Diagramas de Venn</h3> 
<p>Los diagramas de Venn son representaciones gráficas que muestran las relaciones entre los diferentes eventos dentro del espacio muestral. 
  Permiten visualizar las operaciones de unión e intersección entre eventos.</p> 
  
  <h4>Ejemplo de diagrama de Venn</h4> 
  <pre>Ω
    ┌───────┐
    │       │
    │   A   │
    │       │
    │       │
    │   B   │
    │       │
    │       │
    └───────┘ </pre>
  <p>En este diagrama, el espacio muestral <strong>Ω</strong> está representado por el rectángulo, y los eventos <strong>A y B</strong> se representan como subconjuntos dentro del espacio muestral.</p>
 

<h2>2.4 Probabilidad con Técnicas de Conteo</h2>

<h3>Axiomas de la Probabilidad</h3>
<ul>
  <li><strong>Axioma 1: </strong>La probabilidad de cualquier evento A es un número no negativo, es decir, P(A) ≥ 0.</li>
  <li><strong>Axioma 2: </strong>La probabilidad del espacio muestral Ω es 1, es decir, P(Ω) = 1.</li>
  <li><strong>Axioma 3: </strong>La probabilidad de la unión de eventos mutuamente excluyentes A1, A2, ...,
     An es la suma de sus probabilidades individuales, es decir, P(A1 ∪ A2 ∪ ... ∪ An) = P(A1) + P(A2) + ... + P(An).</li>

</ul>
<h3>Teoremas de Probabilidad:</h3>

<ul>
  <li><strong>Teorema de Complementación: </strong>La probabilidad del complemento de un evento A es 1 menos la probabilidad de A, es decir, P(A') = 1 - P(A).</li>
  <li><strong>Teorema de la Adición: </strong>La probabilidad de la unión de dos eventos A y B es igual a la suma de sus probabilidades individuales menos la probabilidad 
    de su intersección, es decir, P(A ∪ B) = P(A) + P(B) - P(A ∩ B).</li>
  <li><strong>Teorema de la Multiplicación: </strong>La probabilidad de la intersección de dos eventos A y B (eventos dependientes) es igual al producto de la probabilidad
     de A y la probabilidad de B dado que A ha ocurrido, es decir, P(A ∩ B) = P(A) * P(B|A).</li>
  <li><strong>Teorema de la Probabilidad Total: </strong>La probabilidad de un evento A es igual a la suma de los productos de las probabilidades de los eventos que forman
     una partición del espacio muestral, multiplicadas por las probabilidades condicionales de A dado cada uno de esos eventos.</li>
</ul>


<h2>2.5 Probabilidad condicional</h2>

<p>La probabilidad condicional es la probabilidad de que ocurra un evento <strong>A</strong> dado que ha ocurrido otro evento <strong>B.</strong> 
  Se denota como <strong>P(A|B)</strong> y se lee "la probabilidad de <strong>A</strong>, dado <strong>B</strong>".</p>

<h3>Probabilidad Condicional Dependiente</h3>
<p>Cuando la ocurrencia de un evento afecta la probabilidad de ocurrencia de otro evento, se dice que los eventos son dependientes. 
  En este caso, la probabilidad condicional <strong>P(A|B)</strong> es diferente a la probabilidad marginal <strong>P(A).</strong>
  Fórmula de Probabilidad Condicional Dependiente:
  <strong>(A|B) = P(A ∩ B) / P(B)</strong>
  </p>

<h3>Probabilidad Condicional Independiente</h3>
<p>Cuando la ocurrencia de un evento no afecta la probabilidad de ocurrencia de otro evento, se dice que los eventos son independientes.
  En este caso, la probabilidad condicional <strong>(A|B)</strong> es igual a la probabilidad marginal <strong>(A).</strong>
  Fórmula de Probabilidad Condicional Independiente:
  <strong>(A|B) = P(A)</strong>
  Teorema de la Multiplicación para Eventos Independientes:
  <strong>(A ∩ B) = P(A) * P(B)</strong></p>



<h2>2.6 Ley multiplicativa</h2>

<p>La probabilidad de la intersección de dos eventos <strong>A</strong> y <strong>B</strong> se calcula como: <br>
  <strong>(A ∩ B) = P(A) * P(B|A)</strong> <br>
  Donde:
</p>

<ul>
  <li><strong>P(A ∩ B) </strong>es la probabilidad de la intersección de <strong>A</strong> y <strong>B.</strong></li>
  <li><strong>P(A) </strong>es la probabilidad del evento <strong>A.</strong></li>
  <li><strong>P(B|A) </strong>es la probabilidad del evento B dado que ha ocurrido el evento <strong>A.</strong></li>
</ul>

<p>
  Esta fórmula se aplica tanto para eventos dependientes como independientes.
  Para eventos independientes, la expresión se simplifica a:
  <strong>P(A ∩ B) = P(A) * P(B)</strong>
La ley multiplicativa es fundamental en el cálculo de probabilidades conjuntas.
</p>

<h2>2.7 Eventos independientes</h2>

<h3>Regla de Bayes para Eventos Independientes</h3>
<p><strong>P(A|B) = (P(B|A) * P(A)) / P(B)</strong> <br>
  Donde:
</p>

<ul>
  <li><strong>P(A|B) </strong>es la probabilidad de <strong>A</strong> dado <strong>B.</strong></li>
  <li><strong>P(B|A) </strong>es la probabilidad de <strong>B</strong> dado <strong>A.</strong></li>
  <li><strong>P(A) </strong>es la probabilidad de <strong>A.</strong></li>
  <li><strong>P(B) </strong>es la probabilidad de <strong>B.</strong></li>
</ul>

<p>Esta regla permite calcular la probabilidad condicional inversa para eventos independientes.</p>

<h1>Tema 3</h1>

<h2>3.1 Variables aleatorias discretas</h2>

<p><strong>Distribución de probabilidad en forma general:</strong> Una distribución de probabilidad describe la probabilidad de que una 
  variable aleatoria tome ciertos valores. La forma general de una distribución de probabilidad se puede escribir como:
  <br><strong>P(X = x) = f(x)</strong><br>
  Donde X es la variable aleatoria y <strong>f(x)</strong> es la función de probabilidad.</p>

<p><strong>Valor esperado:</strong> El valor esperado, también conocido como la media, representa el valor promedio o central de una variable aleatoria.
   Se calcula como la suma de los productos de cada posible valor por su respectiva probabilidad:
   <br><strong>E(X) = Σ x * P(X = x)</strong></p>

<p><strong>Variancia y desviación estándar:</strong>
  La variancia mide qué tan dispersos están los valores de una variable aleatoria con respecto a su media. Se calcula como:
  <br> <strong>Var(X) = E[(X - E(X))^2]</strong><br>
  La desviación estándar es la raíz cuadrada de la variancia:
  <br><strong> σ = √Var(X)</strong></p>

<p><strong> Función acumulada:</strong>
  La función de distribución acumulada <strong>(CDF)</strong> de una variable aleatoria <strong>X</strong> se denota como <strong>F(x)</strong> y se define como la probabilidad de que <strong>X</strong> tome un valor menor o igual a <strong>x</strong>:
  <br><strong>F(x) = P(X ≤ x)</strong><br>
  La <strong>CDF</strong> proporciona información sobre la probabilidad de que la variable aleatoria tome un valor menor o igual a un valor específico.</p>

<h2>3.2 Variables aleatorias Continuas</h2>

<p><strong>Distribución de probabilidad en forma general:</strong>
  La forma general de una distribución de probabilidad se puede escribir como:
<br><strong>P(X = x) = f(x)</strong><br>
  Donde <strong>X</strong> es la variable aleatoria y <strong>f(x)</strong> es la función de probabilidad.</p>

<p><strong>Valor esperado:</strong>
  El valor esperado, también conocido como la media, se calcula como la suma de los productos de cada posible valor por su respectiva probabilidad:
<br><strong>E(X) = Σ x * P(X = x)</strong></p>

<p><strong>Variancia y desviación estándar:</strong>
  La variancia mide qué tan dispersos están los valores de una variable aleatoria con respecto a su media:
<br><strong>Var(X) = E[(X - E(X))^2]</strong><br>
  La desviación estándar es la raíz cuadrada de la variancia:
<br><strong>σ = √Var(X)</strong></p>

<p><strong>Función acumulada:</strong>
  La función de distribución acumulada <strong>(CDF)</strong> de una variable aleatoria <strong>X</strong> se define como la probabilidad de que <strong>X</strong> tome un valor menor o igual a <strong>x</strong>:
<strong>F(x) = P(X ≤ x)</strong></p>

<p><strong>Cálculos de probabilidad:</strong>
  Los cálculos de probabilidad involucran el uso de las distribuciones de probabilidad, el valor esperado, la variancia y la función acumulada para determinar la probabilidad 
  de eventos específicos o la probabilidad de que una variable aleatoria tome un valor dentro de cierto rango.</p>

<h1>Tema 4</h1>

<h2>4.1 Función de probabilidad.</h2>
<p>La función de probabilidad <strong>P(X=x)</strong> asigna la probabilidad de que una variable aleatoria <strong>X</strong> tome un valor específico <strong>x.</strong><br>
  Es una función que cumple con las siguientes propiedades: <br>
<strong>P(X=x) ≥ 0</strong> para todo <strong>x</strong> (las probabilidades son no negativas)<br>
<strong>Σ P(X=x) = 1</strong>, donde la suma se realiza sobre todos los posibles valores de <strong>X</strong> (la suma de todas las probabilidades es 1)<br>
  Existen diferentes tipos de funciones de probabilidad, como la discreta y la continua, dependiendo del tipo de variable aleatoria.</p>

<h2>4.2 Distribución binomial</h2>
<p>Es una distribución de probabilidad discreta utilizada cuando se tienen n ensayos independientes, cada uno con dos posibles resultados (éxito o fracaso).<br>
  Los parámetros que la caracterizan son:
  <ul>
    <li><strong>n: </strong>número de ensayos</li>
    <li><strong>p: </strong>probabilidad de éxito en cada ensayo</li>
  </ul>
  La función de probabilidad está dada por: <strong>P(X=x) = (n! / (x! * (n-x)!)) * p^x * (1-p)^(n-x)</strong><br>
  Algunas propiedades importantes:

  <ul>
    <li><strong>E[X] = n*p</strong> (media)</li>
    <li><strong>Var(X)= np(1-p)</strong> (varianza)</li>
    <li>La distribución es simétrica si <strong>p = 0.5</strong>, y asimétrica en caso contrario.</li>
  </ul>
  <h5>Función de probabilidad:</h5>
  <img src="./img/binomial.png">
  </p>

<h2>4.3 Distribución hipergeométrica</h2>
<p>
  Es una distribución de probabilidad discreta que modela el número de éxitos en una muestra aleatoria sin reemplazo de una población finita.<br>
  Los parámetros que la caracterizan son:
<ul>
  <li><strong>N: </strong>tamaño de la población</li>
  <li><strong>K: </strong>número de elementos de interés en la población</li>
  <li><strong>n: </strong>tamaño de la muestra</li>
</ul>

  La función de probabilidad está dada por: <strong>P(X=x) = ((K! / (x! * (K-x)!)) * ((N-K)! / ((n-x)! * (N-K-n+x)!))) / (N! / (n! * (N-n)!))</strong><br>
  Algunas propiedades importantes:
  <ul>
    <li><strong>E[X] = n*K/N </strong>(media)</li>
    <li><strong>Var(X) = n*K/N * (N-K)/N * (N-n)/(N-1) </strong>(varianza)</li>
    <li>A diferencia de la binomial, en la hipergeométrica los ensayos no son independientes.</li>
  </ul>
  <h5>Función de probabilidad:</h5>
  <img src="./img/hiper.png">
</p>

<h2>4.4 Distribución de Poisson</h2>
<p>
  Es una distribución de probabilidad discreta que modela el número de eventos independientes que ocurren en un intervalo de tiempo o espacio dado. <br>
  El parámetro que la caracteriza es <strong>λ</strong>, que representa la tasa media de ocurrencia de los eventos. <br>
  La función de probabilidad está dada por: <strong>P(X=x) = e^(-λ) * λ^x / x!</strong> <br>
  Algunas propiedades importantes:

  <ul>
    <li><strong>E[X] = λ </strong>(media)</li>
    <li><strong>Var(X) = λ</strong> (varianza)</li>
    <li>Útil para modelar eventos raros que ocurren de manera independiente en un intervalo de tiempo o espacio.</li>
  </ul>
  <h5>Función de probabilidad:</h5>
  <img src="./img/poisson.png">
</p>

<h2>4.5 Distribución normal</h2>
<p>
  Es una distribución de probabilidad continua, simétrica y unimodal. <br>
  Se caracteriza por dos parámetros: la media <strong>(μ)</strong> y la desviación estándar <strong>(σ).</strong> <br>
  La función de densidad está dada por: <strong>f(x) = (1 / (σ * √(2π))) * e^(-(x-μ)^2 / (2*σ^2)) </strong><br>
  Algunas propiedades importantes:
  <ul>
    <li><strong>E[X] = μ </strong>(media)</li>
    <li><strong>Var(X) = σ^2 </strong>(varianza)</li>
    <li>Es ampliamente utilizada en estadística y probabilidad debido a sus propiedades matemáticas.</li>
  </ul>
  <h5>Función de probabilidad:</h5>
  <img src="./img/normal.png">
</p>

<h2>4.6 Distribución T-student</h2>

<p>
  Es una distribución de probabilidad continua que se utiliza cuando el tamaño de la muestra es pequeño. <br>
  Se caracteriza por un único parámetro: los grados de libertad <strong>(ν)</strong>. <br>
  La función de densidad está dada por: <strong>f(x) = Γ((ν+1)/2) / (√(νπ) * Γ(ν/2)) * (1 + x^2/ν)^(-(ν+1)/2)</strong> <br>
  Algunas propiedades importantes:

  <ul>
    <li><strong>E[X] = 0</strong> (media)</li>
    <li><strong>Var(X) = ν / (ν-2)</strong> (varianza)</li>
    <li>Se utiliza en inferencia estadística, como en la construcción de intervalos de confianza y pruebas de hipótesis.</li>
  </ul>
</p>

<h2>4.7 Distribución Chi cuadrada</h2>

<p>
  Es una distribución de probabilidad continua que se utiliza para modelar la suma de los cuadrados de variables aleatorias normales independientes. <br>
  Se caracteriza por un único parámetro: los grados de libertad <strong>(ν)</strong>. <br>
  La función de densidad está dada por: <strong>f(x) = x^((ν/2)-1) * e^(-x/2) / (2^(ν/2) * Γ(ν/2))</strong>, para <strong>x ≥ 0.</strong> <br>
  Algunas propiedades importantes:

  <ul>
    <li><strong>E[X] = ν</strong> (media)</li>
    <li><strong>Var(X) = 2ν </strong>(varianza)</li>
    <li>Se utiliza en pruebas de bondad de ajuste, análisis de varianza y otros procedimientos estadísticos.</li>
  </ul>
</p>

<h2>4.8 Distribución F</h2>

<p>
  Es una distribución de probabilidad continua que se utiliza cuando se comparan dos varianzas. <br>
  Se caracteriza por dos parámetros: los grados de libertad del numerador <strong>(ν1)</strong> y los grados de libertad del denominador <strong>(ν2)</strong>. <br>
  La función de densidad está dada por: <strong>f(x) = (Γ((ν1+ν2)/2) / (Γ(ν1/2) * Γ(ν2/2))) * (ν1/ν2)^(ν1/2) * x^(ν1/2-1) * (1 + (ν1/ν2)*x)^(-(ν1+ν2)/2) </strong><br>
  Algunas propiedades importantes:

  <ul>
    <li><strong>E[X] = ν2 / (ν2 - 2), si ν2 > 2 </strong>(media)</li>
    <li><strong>Var(X) = 2ν2^2 * (ν1 + ν2 - 2) / (ν1 * (ν2 - 2)^2 * (ν2 - 4)),</strong> si <strong>ν2 > 4</strong> (varianza)</li>
    <li>Se utiliza en análisis de varianza y otros procedimientos estadísticos inferenciales.</li>
  </ul>
</p>

</body>
</html>